{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSvjwmu3vPMR"
   },
   "source": [
    "# Final Project - Reinforcements Learning \n",
    "Hello dear students,<br> this is the template notebook. Please click on the \"File\" tab and then on \"Save a copy into drive\".\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "### Name and ID:\n",
    "Student 1: Avraham Raviv, 204355390\n",
    "<br>\n",
    "Student 2: Yevgeni Berkovitch, 317079234\n",
    "<br><br>\n",
    "<img src=\"https://play-lh.googleusercontent.com/e_oKlKPISbgdzut1H9opevS7-LTB8-8lsmpCdMkhlnqFenZhpjxbLmx7l158-xQQCIY\">\n",
    "\n",
    "### https://github.com/mpSchrader/gym-sokoban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4T3qcykHFi15"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2dah0RrY9Kmj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
    "!pip install 'imageio==2.4.0'\n",
    "!pip install gym\n",
    "!pip install pygame\n",
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install piglet\n",
    "!pip install gym\n",
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install gym_sokoban\n",
    "\n",
    "!imageio_download_bin ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHbKbI7BwIwv"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "1cNdWkV49OqN"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython.display import HTML\n",
    "\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from soko_pap import *\n",
    "\n",
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TxfvY69Czk_n"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pa3tRhUfzEJ4"
   },
   "outputs": [],
   "source": [
    "from gym import logger as gymlogger\n",
    "gymlogger.set_level(40) # error only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7bJeRHbwMIj"
   },
   "source": [
    "# Display utils\n",
    "The cell below contains the video display configuration. No need to make changes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z41WGwQt9i7_"
   },
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "    video = open(filename,'rb').read()\n",
    "    b64 = base64.b64encode(video)\n",
    "    tag = '''\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "    </video>'''.format(b64.decode())\n",
    "\n",
    "    return HTML(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(room_state):\n",
    "    for i in range(room_state.shape[0]):\n",
    "        for j in range(room_state.shape[1]):\n",
    "            if room_state[i][j] == 2:\n",
    "                target = (i, j)\n",
    "\n",
    "    distances = np.zeros(shape=room_state.shape)\n",
    "    visited_cells = set()\n",
    "    cell_queue = deque()\n",
    "\n",
    "    visited_cells.add(target)\n",
    "    cell_queue.appendleft(target)\n",
    "\n",
    "    while len(cell_queue) != 0:\n",
    "        cell = cell_queue.pop()\n",
    "        distance = distances[cell[0]][cell[1]]\n",
    "        for x,y in ((1,0), (-1,-0), (0,1), (0,-1)):\n",
    "            next_cell_x, next_cell_y = cell[0]+x, cell[1]+y\n",
    "            if room_state[next_cell_x][next_cell_y] != 0 and not (next_cell_x, next_cell_y) in visited_cells:\n",
    "                distances[next_cell_x][next_cell_y] = distance + 1\n",
    "                visited_cells.add((next_cell_x, next_cell_y))\n",
    "                cell_queue.appendleft((next_cell_x, next_cell_y))\n",
    "                \n",
    "    return distances   \n",
    "\n",
    "def calc_distances(room_state, distances):\n",
    "    box = None\n",
    "    mover = None\n",
    "    for i in range(room_state.shape[0]):\n",
    "        for j in range(room_state.shape[1]):            \n",
    "            if room_state[i][j] == 4:\n",
    "                box = (i,j)\n",
    "            \n",
    "            if room_state[i][j] == 5:\n",
    "                mover = (i,j)\n",
    "    \n",
    "    return mover, box, distances[box[0]][box[1]]   \n",
    "\n",
    "def box2target_change_reward(room_state, next_room_state, distances):\n",
    "    if np.array_equal(room_state, next_room_state):\n",
    "        return -1.0\n",
    "    \n",
    "    mover, box, t2b = calc_distances(room_state, distances)\n",
    "    n_mover, n_box, n_t2b = calc_distances(next_room_state, distances)\n",
    "    \n",
    "    change_reward = 0.0\n",
    "    if n_t2b < t2b:\n",
    "        change_reward += 5.0\n",
    "    elif n_t2b > t2b:\n",
    "        change_reward -= 5.0\n",
    "        \n",
    "    m2b = np.sqrt((mover[0]-box[0])**2 + (mover[1]-box[1])**2)\n",
    "    n_m2b = np.sqrt((n_mover[0]-n_box[0])**2 + (n_mover[1]-n_box[1])**2)\n",
    "    \n",
    "    if n_m2b < m2b and m2b >= 2:\n",
    "        change_reward += 1.0\n",
    "    elif n_m2b > m2b and n_m2b >= 2:\n",
    "        change_reward -= 1.0\n",
    "        \n",
    "    return change_reward   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6Qnw883yqGH"
   },
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingDQN(Model):\n",
    "    def __init__(self, n_actions):\n",
    "        super(DuelingDQN, self).__init__()\n",
    "        self.conv1 = Conv2D(32, (16,16), strides=(16,16), activation='relu')\n",
    "        self.conv2 = Conv2D(64, (3,3), activation='relu')\n",
    "        self.conv3 = Conv2D(64, (3,3), padding='same', activation='relu')\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(512, activation='relu')\n",
    "        self.dense2 = Dense(128, activation='relu')\n",
    "        self.dense3 = Dense(32, activation='relu')\n",
    "        self.V = Dense(1, activation=None)\n",
    "        self.A = Dense(n_actions, activation=None)\n",
    "        \n",
    "    def call(self, state):\n",
    "        x = self.conv1(state)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        V = self.V(x)\n",
    "        A = self.A(x)\n",
    "        Q = V + (A - tf.math.reduce_mean(A, axis=1, keepdims=True))\n",
    "        return Q\n",
    "    \n",
    "    def advantage(self, state):\n",
    "        x = self.dense1(state)\n",
    "        x = self.dense2(x)\n",
    "        A = self.A(x)\n",
    "        return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"dueling_dqn_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_6 (Conv2D)           multiple                  0 (unused)\n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           multiple                  0 (unused)\n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           multiple                  0 (unused)\n",
      "                                                                 \n",
      " flatten_2 (Flatten)         multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_12 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_13 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      " dense_14 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "agent.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "gGl0DQvSQG0d"
   },
   "outputs": [],
   "source": [
    "class SOK_Agent:\n",
    "    def __init__(self):\n",
    "        # Dimensions\n",
    "        self.state_size = (112,112,1) \n",
    "        self.action_size = 8    \n",
    "        self.batch_size = 8\n",
    "        \n",
    "        # Replay buffers\n",
    "        self.replay_buffer = deque(maxlen=5000)\n",
    "        self.prioritized_replay_buffer = deque(maxlen=500)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.gamma = 0.9\n",
    "        self.epsilon = 1.0   \n",
    "        self.epsilon_min = 0.3\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.replay_rate = 10\n",
    "        self.update_beta = 0.99\n",
    "        \n",
    "        # Models\n",
    "        self.model = DuelingDQN(self.action_size)\n",
    "        self.target_model = DuelingDQN(self.action_size)\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        \n",
    "        self.model.compile(loss='mse', optimizer=\"adam\")\n",
    "        self.target_model.compile(loss='mse', optimizer=\"adam\")\n",
    "        \n",
    "        # Rotations\n",
    "        self.action_rotation_map = {\n",
    "            0: 2,\n",
    "            1: 3,\n",
    "            2: 1,\n",
    "            3: 0,\n",
    "            4: 6,\n",
    "            5: 7,\n",
    "            6: 5,\n",
    "            7: 4\n",
    "        }\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append([state, action, reward, next_state, done])    \n",
    "        \n",
    "    def copy_to_prioritized_buffer(self, n):\n",
    "        for i in range(n):\n",
    "            self.prioritized_replay_buffer.append(self.replay_buffer[-1-i])  \n",
    "\n",
    "    def act(self, state, stochastic=False):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        state = state.reshape(1, 112, 112, 1)\n",
    "        \n",
    "        act_values = self.model.predict(state, verbose=0)[0]\n",
    "        \n",
    "        if stochastic:\n",
    "            act_probs = np.exp(act_values)/np.exp(act_values).sum()\n",
    "            return np.random.choice(np.arange(self.action_size), size=1, p=act_probs)[0]\n",
    "              \n",
    "        return np.argmax(act_values) \n",
    "\n",
    "    def replay(self): \n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        if len(self.prioritized_replay_buffer) < self.batch_size//2:\n",
    "            minibatch = random.sample(self.replay_buffer, self.batch_size) \n",
    "        else:    \n",
    "            minibatch = random.sample(self.replay_buffer, self.batch_size//2) \n",
    "            minibatch.extend(random.sample(self.prioritized_replay_buffer, self.batch_size//2))\n",
    "        \n",
    "        states = np.zeros((self.batch_size*4, self.state_size[0], self.state_size[1]))\n",
    "        actions = np.zeros(self.batch_size*4, dtype=int)\n",
    "        rewards = np.zeros(self.batch_size*4)\n",
    "        next_states = np.zeros((self.batch_size*4, self.state_size[0], self.state_size[1]))\n",
    "        statuses = np.zeros(self.batch_size*4)\n",
    "        \n",
    "        for i, (state, action, reward, next_state, done) in enumerate(minibatch): \n",
    "            for rot in range(4):  \n",
    "                ind = i*4+rot\n",
    "                if rot != 0:\n",
    "                    state = np.rot90(state, axes=(1,2))\n",
    "                    next_state = np.rot90(next_state, axes=(1,2))\n",
    "                    action = self.action_rotation_map.get(action)\n",
    "\n",
    "                states[ind] = state.copy()\n",
    "                actions[ind] = action\n",
    "                rewards[ind] = reward\n",
    "                next_states[ind] = next_state.copy()\n",
    "                statuses[ind] = 1 if done else 0          \n",
    "        \n",
    "        states = states.reshape(32, 112, 112, 1)\n",
    "        next_states = next_states.reshape(32, 112, 112, 1)\n",
    "        q_pred = self.model.predict(states)         \n",
    "        q_next = self.target_model.predict(next_states)\n",
    "        \n",
    "        q_target = q_pred.copy()\n",
    "        max_actions = tf.math.argmax(self.model.predict(next_states), axis=1)\n",
    "        \n",
    "        for (idx, terminal) in enumerate(statuses):\n",
    "            q_target[idx, actions[idx]] = rewards[idx] + self.gamma * q_next[idx, max_actions[idx]] * (1 - int(statuses[idx]))\n",
    "\n",
    "        self.model.fit(states, q_target, epochs=10, verbose=0) \n",
    "        \n",
    "        self.update_target_model()        \n",
    "    \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon = self.epsilon * self.epsilon_decay    \n",
    "        \n",
    "    def update_target_model(self):\n",
    "        model_w = self.model.get_weights()\n",
    "        target_model_w = self.target_model.get_weights()\n",
    "        updated_target_model_w = []\n",
    "        for i in range(len(model_w)):\n",
    "            updated_target_model_w.append(self.update_beta*target_model_w[i] + (1-self.update_beta)*model_w[i])\n",
    "        self.target_model.set_weights(updated_target_model_w)    \n",
    "            \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "I8TqYhBX1lD4"
   },
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    f = frame.mean(axis=2)\n",
    "    f = f / 255\n",
    "    return np.expand_dims(f, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(e, stochastic=False):\n",
    "    current_epsilon = agent.epsilon\n",
    "    agent.epsilon = 0.0\n",
    "    num_solved = 0\n",
    "    solved_in_steps = defaultdict(int)\n",
    "\n",
    "    for t in tqdm(range(100)):    \n",
    "        random.seed(t)\n",
    "        sok = PushAndPullSokobanEnv(dim_room=(7, 7), num_boxes=1)\n",
    "        sok.set_maxsteps(20)\n",
    "        steps = 0\n",
    "\n",
    "        state = sok.get_image('rgb_array')\n",
    "        done = False\n",
    "        while not done:\n",
    "            steps += 1\n",
    "            action = agent.act(process_frame(state), stochastic)\n",
    "            if action < 4:\n",
    "                action += 1\n",
    "            else:\n",
    "                action += 5\n",
    "            state, reward, done, info = sok.step(action)\n",
    "\n",
    "        if 3 in sok.room_state:            \n",
    "            num_solved += 1\n",
    "            solved_in_steps[steps] += 1\n",
    "    \n",
    "    agent.epsilon = current_epsilon    \n",
    "    print(\"Episode %d Solved: %d\" % (e+1, num_solved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "nuL03AOxCBOK"
   },
   "outputs": [],
   "source": [
    "max_episodes = 50000\n",
    "max_steps = 20\n",
    "\n",
    "def init_sok(r):\n",
    "    random.seed(r+100)\n",
    "    sok = PushAndPullSokobanEnv(dim_room=(7, 7), num_boxes=1)\n",
    "    sok.set_maxsteps(max_steps)\n",
    "    return sok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s2Km5jCqDqbz",
    "outputId": "abab4d45-7d3a-4a49-8b54-10c34549249d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 | 20\n",
      "5 | 40\n",
      "8 | 60\n",
      "14 | 80\n",
      "23 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b777abddae4928a63b25e26aa7e54f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 100 Solved: 34\n",
      "10 | 20\n",
      "17 | 40\n",
      "27 | 60\n",
      "40 | 80\n",
      "51 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db5a4bbea6044ecb97d7f18c0158181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 200 Solved: 59\n",
      "10 | 20\n",
      "24 | 40\n",
      "35 | 60\n",
      "43 | 80\n",
      "52 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebac6d5f3d0946f7987670a0df2e72a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 300 Solved: 63\n",
      "14 | 20\n",
      "26 | 40\n",
      "36 | 60\n",
      "44 | 80\n",
      "52 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb21bc9b9b3408c88b6146feed9cdb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 400 Solved: 68\n",
      "13 | 20\n",
      "23 | 40\n",
      "36 | 60\n",
      "48 | 80\n",
      "64 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54bd5d968ac4e8b9472c206c78f97a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 500 Solved: 71\n",
      "14 | 20\n",
      "31 | 40\n",
      "39 | 60\n",
      "53 | 80\n",
      "64 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ad31c75ac0a4ba9b861fed63ed9c9e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 600 Solved: 72\n",
      "10 | 20\n",
      "22 | 40\n",
      "39 | 60\n",
      "52 | 80\n",
      "60 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d31dec1fcd040a09fdc519e7c360cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 700 Solved: 70\n",
      "7 | 20\n",
      "18 | 40\n",
      "34 | 60\n",
      "50 | 80\n",
      "65 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130c39a3287a400a9a887800d8b9701c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 800 Solved: 77\n",
      "14 | 20\n",
      "23 | 40\n",
      "33 | 60\n",
      "43 | 80\n",
      "56 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08ef12b6a3e94ff5b09f35a0d199db8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 900 Solved: 79\n",
      "9 | 20\n",
      "22 | 40\n",
      "37 | 60\n",
      "49 | 80\n",
      "65 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a8e61dc9d0244f78d3417c8565c31f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = SOK_Agent()\n",
    "\n",
    "running_puzzles = 0\n",
    "running_solved = 0\n",
    "\n",
    "for e in range(max_episodes):\n",
    "    sok = init_sok(e)\n",
    "    random.seed(e)\n",
    "    running_puzzles += 1\n",
    "    \n",
    "    state = process_frame(sok.get_image('rgb_array'))\n",
    "    room_state = sok.room_state.copy() \n",
    "    distances = get_distances(room_state)\n",
    "    \n",
    "    for step in range(sok.max_steps):\n",
    "        action = agent.act(state)\n",
    "        if action < 4:\n",
    "            next_state, reward, done, _ = sok.step(action+1) \n",
    "        else:\n",
    "            next_state, reward, done, _ = sok.step(action+5)         \n",
    "        \n",
    "        next_state = process_frame(next_state)        \n",
    "        next_room_state = sok.room_state\n",
    "        \n",
    "        if not done:\n",
    "            reward += box2target_change_reward(room_state, next_room_state, distances)\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state.copy() \n",
    "        room_state = next_room_state.copy()                \n",
    "        \n",
    "        if (step+1) % agent.replay_rate == 0:\n",
    "            agent.replay()            \n",
    "        \n",
    "        if done: \n",
    "            if 3 in sok.room_state:  \n",
    "                agent.copy_to_prioritized_buffer(step+1)  \n",
    "                running_solved += 1\n",
    "                \n",
    "            if (e+1) % 20 == 0 and e > 0:\n",
    "                print(f\"{running_solved} | {running_puzzles}\") \n",
    "                \n",
    "                if (e+1) % 100 == 0:\n",
    "                    running_puzzles = 0\n",
    "                    running_solved = 0\n",
    "                    \n",
    "            break\n",
    "            \n",
    "    if (e+1) % 100 == 0 and e > 0:\n",
    "        test_agent(e, stochastic=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
