{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSvjwmu3vPMR"
   },
   "source": [
    "# Final Project - Reinforcements Learning \n",
    "Hello dear students,<br> this is the template notebook. Please click on the \"File\" tab and then on \"Save a copy into drive\".\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "### Name and ID:\n",
    "Student 1: Avraham Raviv, 204355390\n",
    "<br>\n",
    "Student 2: Yevgeni Berkovitch, 317079234\n",
    "<br><br>\n",
    "<img src=\"https://play-lh.googleusercontent.com/e_oKlKPISbgdzut1H9opevS7-LTB8-8lsmpCdMkhlnqFenZhpjxbLmx7l158-xQQCIY\">\n",
    "\n",
    "### https://github.com/mpSchrader/gym-sokoban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4T3qcykHFi15"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2dah0RrY9Kmj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
    "!pip install 'imageio==2.4.0'\n",
    "!pip install gym\n",
    "!pip install pygame\n",
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install piglet\n",
    "!pip install gym\n",
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install gym_sokoban\n",
    "\n",
    "!imageio_download_bin ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHbKbI7BwIwv"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1cNdWkV49OqN"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython.display import HTML\n",
    "\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from soko_pap import *\n",
    "\n",
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TxfvY69Czk_n"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pa3tRhUfzEJ4"
   },
   "outputs": [],
   "source": [
    "from gym import logger as gymlogger\n",
    "gymlogger.set_level(40) # error only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7bJeRHbwMIj"
   },
   "source": [
    "# Display utils\n",
    "The cell below contains the video display configuration. No need to make changes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z41WGwQt9i7_"
   },
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "    video = open(filename,'rb').read()\n",
    "    b64 = base64.b64encode(video)\n",
    "    tag = '''\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "    </video>'''.format(b64.decode())\n",
    "\n",
    "    return HTML(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(room_state):\n",
    "    for i in range(room_state.shape[0]):\n",
    "        for j in range(room_state.shape[1]):\n",
    "            if room_state[i][j] == 2:\n",
    "                target = (i, j)\n",
    "\n",
    "    distances = np.zeros(shape=room_state.shape)\n",
    "    visited_cells = set()\n",
    "    cell_queue = deque()\n",
    "\n",
    "    visited_cells.add(target)\n",
    "    cell_queue.appendleft(target)\n",
    "\n",
    "    while len(cell_queue) != 0:\n",
    "        cell = cell_queue.pop()\n",
    "        distance = distances[cell[0]][cell[1]]\n",
    "        for x,y in ((1,0), (-1,-0), (0,1), (0,-1)):\n",
    "            next_cell_x, next_cell_y = cell[0]+x, cell[1]+y\n",
    "            if room_state[next_cell_x][next_cell_y] != 0 and not (next_cell_x, next_cell_y) in visited_cells:\n",
    "                distances[next_cell_x][next_cell_y] = distance + 1\n",
    "                visited_cells.add((next_cell_x, next_cell_y))\n",
    "                cell_queue.appendleft((next_cell_x, next_cell_y))\n",
    "                \n",
    "    return distances   \n",
    "\n",
    "def calc_distances(room_state, distances):\n",
    "    box = None\n",
    "    mover = None\n",
    "    for i in range(room_state.shape[0]):\n",
    "        for j in range(room_state.shape[1]):            \n",
    "            if room_state[i][j] == 4:\n",
    "                box = (i,j)\n",
    "            \n",
    "            if room_state[i][j] == 5:\n",
    "                mover = (i,j)\n",
    "    \n",
    "    return mover, box, distances[box[0]][box[1]]   \n",
    "\n",
    "def box2target_change_reward(room_state, next_room_state, distances):\n",
    "    if np.array_equal(room_state, next_room_state):\n",
    "        return -1.0\n",
    "    \n",
    "    mover, box, t2b = calc_distances(room_state, distances)\n",
    "    n_mover, n_box, n_t2b = calc_distances(next_room_state, distances)\n",
    "    \n",
    "    change_reward = 0.0\n",
    "    if n_t2b < t2b:\n",
    "        change_reward += 5.0\n",
    "    elif n_t2b > t2b:\n",
    "        change_reward -= 5.0\n",
    "        \n",
    "    m2b = np.sqrt((mover[0]-box[0])**2 + (mover[1]-box[1])**2)\n",
    "    n_m2b = np.sqrt((n_mover[0]-n_box[0])**2 + (n_mover[1]-n_box[1])**2)\n",
    "    \n",
    "    if n_m2b < m2b and m2b >= 2:\n",
    "        change_reward += 1.0\n",
    "    elif n_m2b > m2b and n_m2b >= 2:\n",
    "        change_reward -= 1.0\n",
    "        \n",
    "    return change_reward   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6Qnw883yqGH"
   },
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "gGl0DQvSQG0d"
   },
   "outputs": [],
   "source": [
    "class SOK_Agent:\n",
    "    def __init__(self):\n",
    "        # Construct DQN models\n",
    "        self.state_size = (112,112,1) \n",
    "        self.action_size = 8\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        self.batch_size = 8\n",
    "        \n",
    "        # Replay buffers\n",
    "        self.replay_buffer = deque(maxlen=5000)\n",
    "        self.prioritized_replay_buffer = deque(maxlen=500)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.gamma = 0.9\n",
    "        self.epsilon = 1.0   \n",
    "        self.epsilon_min = 0.3\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.replay_rate = 10\n",
    "        self.update_beta = 0.99\n",
    "        \n",
    "        self.action_rotation_map = {\n",
    "            0: 2,\n",
    "            1: 3,\n",
    "            2: 1,\n",
    "            3: 0,\n",
    "            4: 6,\n",
    "            5: 7,\n",
    "            6: 5,\n",
    "            7: 4\n",
    "        }\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (16,16), strides=(16,16), input_shape=self.state_size, activation='relu'))\n",
    "        model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "        model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))       \n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=\"adam\")        \n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append([state, action, reward, next_state, done])    \n",
    "        \n",
    "    def copy_to_prioritized_buffer(self, n):\n",
    "        for i in range(n):\n",
    "            self.prioritized_replay_buffer.append(self.replay_buffer[-1-i])  \n",
    "\n",
    "    def act(self, state, stochastic=False):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        act_values = self.model.predict(state, verbose=0)[0]\n",
    "        \n",
    "        if stochastic:\n",
    "            act_probs = np.exp(act_values)/np.exp(act_values).sum()\n",
    "            return np.random.choice(np.arange(self.action_size), size=1, p=act_probs)[0]\n",
    "              \n",
    "        return np.argmax(act_values) \n",
    "\n",
    "    def replay(self): \n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        if len(self.prioritized_replay_buffer) < self.batch_size//2:\n",
    "            minibatch = random.sample(self.replay_buffer, self.batch_size) \n",
    "        else:    \n",
    "            minibatch = random.sample(self.replay_buffer, self.batch_size//2) \n",
    "            minibatch.extend(random.sample(self.prioritized_replay_buffer, self.batch_size//2))\n",
    "        \n",
    "        states = np.zeros((self.batch_size*4, self.state_size[0], self.state_size[1]))\n",
    "        actions = np.zeros(self.batch_size*4, dtype=int)\n",
    "        rewards = np.zeros(self.batch_size*4)\n",
    "        next_states = np.zeros((self.batch_size*4, self.state_size[0], self.state_size[1]))\n",
    "        statuses = np.zeros(self.batch_size*4)\n",
    "        targets = np.zeros((self.batch_size*4, self.action_size)) \n",
    "        \n",
    "        for i, (state, action, reward, next_state, done) in enumerate(minibatch): \n",
    "            for rot in range(4):  \n",
    "                ind = i*4+rot\n",
    "                if rot != 0:\n",
    "                    state = np.rot90(state, axes=(1,2))\n",
    "                    next_state = np.rot90(next_state, axes=(1,2))\n",
    "                    action = self.action_rotation_map.get(action)\n",
    "\n",
    "                states[ind] = state.copy()\n",
    "                actions[ind] = action\n",
    "                rewards[ind] = reward\n",
    "                next_states[ind] = next_state.copy()\n",
    "                statuses[ind] = 1 if done else 0          \n",
    "        \n",
    "        targets = self.model.predict(states) \n",
    "        max_actions = np.argmax(self.model.predict(next_states), axis=1)\n",
    "        next_rewards = self.target_model.predict(next_states)\n",
    "        \n",
    "        ind = 0\n",
    "        for action, reward, next_reward, max_action, done in zip(actions, rewards, next_rewards, max_actions, statuses):  \n",
    "            if not done:\n",
    "                reward += self.gamma * next_reward[max_action]\n",
    "            targets[ind][action] = reward\n",
    "            ind += 1\n",
    "        \n",
    "        self.model.fit(states, targets, epochs=10, verbose=0) \n",
    "        \n",
    "        self.update_target_model()        \n",
    "    \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon = self.epsilon * self.epsilon_decay    \n",
    "        \n",
    "    def update_target_model(self):\n",
    "        model_w = self.model.get_weights()\n",
    "        target_model_w = self.target_model.get_weights()\n",
    "        updated_target_model_w = []\n",
    "        for i in range(len(model_w)):\n",
    "            updated_target_model_w.append(self.update_beta*target_model_w[i] + (1-self.update_beta)*model_w[i])\n",
    "        self.target_model.set_weights(updated_target_model_w)    \n",
    "            \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "I8TqYhBX1lD4"
   },
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    f = frame.mean(axis=2)\n",
    "    f = f / 255\n",
    "    return np.expand_dims(f, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(e, stochastic=False):\n",
    "    current_epsilon = agent.epsilon\n",
    "    agent.epsilon = 0.0\n",
    "    num_solved = 0\n",
    "    solved_in_steps = defaultdict(int)\n",
    "\n",
    "    for t in tqdm(range(100)):    \n",
    "        random.seed(t)\n",
    "        sok = PushAndPullSokobanEnv(dim_room=(7, 7), num_boxes=1)\n",
    "        sok.set_maxsteps(20)\n",
    "        steps = 0\n",
    "\n",
    "        state = sok.get_image('rgb_array')\n",
    "        done = False\n",
    "        while not done:\n",
    "            steps += 1\n",
    "            action = agent.act(process_frame(state), stochastic)\n",
    "            if action < 4:\n",
    "                action += 1\n",
    "            else:\n",
    "                action += 5\n",
    "            state, reward, done, info = sok.step(action)\n",
    "\n",
    "        if 3 in sok.room_state:            \n",
    "            num_solved += 1\n",
    "            solved_in_steps[steps] += 1\n",
    "    \n",
    "    agent.epsilon = current_epsilon    \n",
    "    print(\"Episode %d Solved: %d\" % (e+1, num_solved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nuL03AOxCBOK"
   },
   "outputs": [],
   "source": [
    "max_episodes = 50000\n",
    "max_steps = 20\n",
    "\n",
    "def init_sok(r):\n",
    "    random.seed(r+100)\n",
    "    sok = PushAndPullSokobanEnv(dim_room=(7, 7), num_boxes=1)\n",
    "    sok.set_maxsteps(max_steps)\n",
    "    return sok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s2Km5jCqDqbz",
    "outputId": "abab4d45-7d3a-4a49-8b54-10c34549249d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 | 20\n",
      "4 | 40\n",
      "9 | 60\n",
      "16 | 80\n",
      "23 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b164d7b97e4c83b5660cbbcbb084fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 100 Solved: 27\n",
      "6 | 20\n",
      "9 | 40\n",
      "14 | 60\n",
      "24 | 80\n",
      "31 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275b0ccf73d04696b688aea2d8d8d4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 200 Solved: 41\n",
      "8 | 20\n",
      "19 | 40\n",
      "28 | 60\n",
      "35 | 80\n",
      "40 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37eff91239364a798627b22c75afe6e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 300 Solved: 45\n",
      "6 | 20\n",
      "16 | 40\n",
      "24 | 60\n",
      "31 | 80\n",
      "37 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c455da21154d43ea90aae6f05a0487ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 400 Solved: 47\n",
      "10 | 20\n",
      "19 | 40\n",
      "25 | 60\n",
      "33 | 80\n",
      "44 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05ae0f19254949bbbba34e6d79af236f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 500 Solved: 64\n",
      "12 | 20\n",
      "24 | 40\n",
      "34 | 60\n",
      "42 | 80\n",
      "50 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1917e7318481448ab226933d0eeec23c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 600 Solved: 58\n",
      "12 | 20\n",
      "24 | 40\n",
      "39 | 60\n",
      "51 | 80\n",
      "58 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222bfa81f5ae4175bb81835e4ffeb924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 700 Solved: 65\n",
      "8 | 20\n",
      "14 | 40\n",
      "26 | 60\n",
      "39 | 80\n",
      "48 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3208b4a43461439abfbb90fecab34d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 800 Solved: 53\n",
      "8 | 20\n",
      "16 | 40\n",
      "27 | 60\n",
      "37 | 80\n",
      "47 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d627d7526fe4619b07b5dea09dd5288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-eb563d28cf2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mtest_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-d14adf7a1311>\u001b[0m in \u001b[0;36mtest_agent\u001b[1;34m(e, stochastic)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0msok\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPushAndPullSokobanEnv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_room\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0msok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_maxsteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dim_room, max_steps, num_boxes, num_gen_steps)\u001b[0m\n\u001b[0;32m   1013\u001b[0m              num_gen_steps=None):\n\u001b[0;32m   1014\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1015\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPushAndPullSokobanEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim_room\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_boxes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_gen_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1016\u001b[0m         \u001b[0mscreen_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdim_room\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_room\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhigh\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscreen_height\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dim_room, max_steps, num_boxes, num_gen_steps, reset)\u001b[0m\n\u001b[0;32m    749\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[1;31m# Initialize Room\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mreset\u001b[1;34m(self, second_player, render_mode)\u001b[0m\n\u001b[0;32m    905\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecond_player\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrender_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rgb_array'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m             self.room_fixed, self.room_state, self.box_mapping = generate_room(\n\u001b[0m\u001b[0;32m    908\u001b[0m                 \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_room\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m                 \u001b[0mnum_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_gen_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mgenerate_room\u001b[1;34m(dim, p_change_directions, num_steps, num_boxes, tries, second_player)\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mroom_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroom_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 383\u001b[1;33m         \u001b[0mroom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreverse_playing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroom_structure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    384\u001b[0m         \u001b[0mroom_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mroom_state\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mreverse_playing\u001b[1;34m(room_state, room_structure, search_depth)\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[0mbest_room_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[0mbest_box_mapping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbox_mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m     \u001b[0mdepth_first_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroom_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_mapping\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_pull\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mttl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_room\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_room_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_box_mapping\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    610\u001b[0m                 \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 612\u001b[1;33m             depth_first_search(room_state_next, room_structure,\n\u001b[0m\u001b[0;32m    613\u001b[0m                                \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_swaps_next\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m                                last_pull, ttl)\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mdepth_first_search\u001b[1;34m(room_state, room_structure, box_mapping, box_swaps, last_pull, ttl)\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m             \u001b[0mroom_state_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_pull_next\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 606\u001b[1;33m                 \u001b[0mreverse_move\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroom_state_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroom_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbox_mapping_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_pull\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    607\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    608\u001b[0m             \u001b[0mbox_swaps_next\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbox_swaps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Reinforce... Learning\\Final_Project\\soko_pap.py\u001b[0m in \u001b[0;36mreverse_move\u001b[1;34m(room_state, room_structure, box_mapping, last_pull, action)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m     \u001b[0mchange\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCHANGE_COORDINATES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maction\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m     \u001b[0mnext_position\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplayer_position\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mchange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m     \u001b[1;31m# Check if next position is an empty floor or an empty box target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = SOK_Agent()\n",
    "\n",
    "running_puzzles = 0\n",
    "running_solved = 0\n",
    "\n",
    "for e in range(max_episodes):\n",
    "    sok = init_sok(e)\n",
    "    random.seed(e)\n",
    "    running_puzzles += 1\n",
    "    \n",
    "    state = process_frame(sok.get_image('rgb_array'))\n",
    "    room_state = sok.room_state.copy() \n",
    "    distances = get_distances(room_state)\n",
    "    \n",
    "    for step in range(sok.max_steps):\n",
    "        action = agent.act(state)\n",
    "        if action < 4:\n",
    "            next_state, reward, done, _ = sok.step(action+1) \n",
    "        else:\n",
    "            next_state, reward, done, _ = sok.step(action+5)         \n",
    "        \n",
    "        next_state = process_frame(next_state)        \n",
    "        next_room_state = sok.room_state\n",
    "        \n",
    "        if not done:\n",
    "            reward += box2target_change_reward(room_state, next_room_state, distances)\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state.copy() \n",
    "        room_state = next_room_state.copy()                \n",
    "        \n",
    "        if (step+1) % agent.replay_rate == 0:\n",
    "            agent.replay()            \n",
    "        \n",
    "        if done: \n",
    "            if 3 in sok.room_state:  \n",
    "                agent.copy_to_prioritized_buffer(step+1)  \n",
    "                running_solved += 1\n",
    "                \n",
    "            if (e+1) % 20 == 0 and e > 0:\n",
    "                print(f\"{running_solved} | {running_puzzles}\") \n",
    "                \n",
    "                if (e+1) % 100 == 0:\n",
    "                    running_puzzles = 0\n",
    "                    running_solved = 0\n",
    "                    \n",
    "            break\n",
    "            \n",
    "    if (e+1) % 100 == 0 and e > 0:\n",
    "        test_agent(e, stochastic=False)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
