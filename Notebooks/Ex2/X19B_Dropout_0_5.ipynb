{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dSvjwmu3vPMR"
   },
   "source": [
    "# Final Project - Reinforcements Learning \n",
    "Hello dear students,<br> this is the template notebook. Please click on the \"File\" tab and then on \"Save a copy into drive\".\n",
    "\n",
    "---\n",
    "<br>\n",
    "\n",
    "### Name and ID:\n",
    "Student 1: Avraham Raviv, 204355390\n",
    "<br>\n",
    "Student 2: Yevgeni Berkovitch, 317079234\n",
    "<br><br>\n",
    "<img src=\"https://play-lh.googleusercontent.com/e_oKlKPISbgdzut1H9opevS7-LTB8-8lsmpCdMkhlnqFenZhpjxbLmx7l158-xQQCIY\">\n",
    "\n",
    "### https://github.com/mpSchrader/gym-sokoban"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4T3qcykHFi15"
   },
   "source": [
    "# Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2dah0RrY9Kmj"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!sudo apt-get update\n",
    "!sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
    "!pip install 'imageio==2.4.0'\n",
    "!pip install gym\n",
    "!pip install pygame\n",
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install piglet\n",
    "!pip install gym\n",
    "!apt-get install python-opengl -y\n",
    "!apt install xvfb -y\n",
    "!pip install gym_sokoban\n",
    "\n",
    "!imageio_download_bin ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yHbKbI7BwIwv"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "1cNdWkV49OqN"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython.display import HTML\n",
    "\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from soko_pap import *\n",
    "\n",
    "from collections import deque\n",
    "from queue import PriorityQueue\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, Dropout, Flatten\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TxfvY69Czk_n"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.plugins.ffmpeg.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pa3tRhUfzEJ4"
   },
   "outputs": [],
   "source": [
    "from gym import logger as gymlogger\n",
    "gymlogger.set_level(40) # error only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7bJeRHbwMIj"
   },
   "source": [
    "# Display utils\n",
    "The cell below contains the video display configuration. No need to make changes here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "z41WGwQt9i7_"
   },
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
    "    video = open(filename,'rb').read()\n",
    "    b64 = base64.b64encode(video)\n",
    "    tag = '''\n",
    "    <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "    Your browser does not support the video tag.\n",
    "    </video>'''.format(b64.decode())\n",
    "\n",
    "    return HTML(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(room_state):\n",
    "    for i in range(room_state.shape[0]):\n",
    "        for j in range(room_state.shape[1]):\n",
    "            if room_state[i][j] == 2:\n",
    "                target = (i, j)\n",
    "\n",
    "    distances = np.zeros(shape=room_state.shape)\n",
    "    visited_cells = set()\n",
    "    cell_queue = deque()\n",
    "\n",
    "    visited_cells.add(target)\n",
    "    cell_queue.appendleft(target)\n",
    "\n",
    "    while len(cell_queue) != 0:\n",
    "        cell = cell_queue.pop()\n",
    "        distance = distances[cell[0]][cell[1]]\n",
    "        for x,y in ((1,0), (-1,-0), (0,1), (0,-1)):\n",
    "            next_cell_x, next_cell_y = cell[0]+x, cell[1]+y\n",
    "            if room_state[next_cell_x][next_cell_y] != 0 and not (next_cell_x, next_cell_y) in visited_cells:\n",
    "                distances[next_cell_x][next_cell_y] = distance + 1\n",
    "                visited_cells.add((next_cell_x, next_cell_y))\n",
    "                cell_queue.appendleft((next_cell_x, next_cell_y))\n",
    "                \n",
    "    return distances   \n",
    "\n",
    "def calc_distances(room_state, distances):\n",
    "    box = None\n",
    "    mover = None\n",
    "    for i in range(room_state.shape[0]):\n",
    "        for j in range(room_state.shape[1]):            \n",
    "            if room_state[i][j] == 4:\n",
    "                box = (i,j)\n",
    "            \n",
    "            if room_state[i][j] == 5:\n",
    "                mover = (i,j)\n",
    "    \n",
    "    return mover, box, distances[box[0]][box[1]]   \n",
    "\n",
    "def box2target_change_reward(room_state, next_room_state, distances):\n",
    "    if np.array_equal(room_state, next_room_state):\n",
    "        return -1.0\n",
    "    \n",
    "    mover, box, t2b = calc_distances(room_state, distances)\n",
    "    n_mover, n_box, n_t2b = calc_distances(next_room_state, distances)\n",
    "    \n",
    "    change_reward = 0.0\n",
    "    if n_t2b < t2b:\n",
    "        change_reward += 5.0\n",
    "    elif n_t2b > t2b:\n",
    "        change_reward -= 5.0\n",
    "        \n",
    "    m2b = np.sqrt((mover[0]-box[0])**2 + (mover[1]-box[1])**2)\n",
    "    n_m2b = np.sqrt((n_mover[0]-n_box[0])**2 + (n_mover[1]-n_box[1])**2)\n",
    "    \n",
    "    if n_m2b < m2b and m2b >= 2:\n",
    "        change_reward += 1.0\n",
    "    elif n_m2b > m2b and n_m2b >= 2:\n",
    "        change_reward -= 1.0\n",
    "        \n",
    "    return change_reward   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I6Qnw883yqGH"
   },
   "source": [
    "# Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "gGl0DQvSQG0d"
   },
   "outputs": [],
   "source": [
    "class SOK_Agent:\n",
    "    def __init__(self):\n",
    "        # Construct DQN models\n",
    "        self.state_size = (112,112,1) \n",
    "        self.action_size = 8\n",
    "        self.model = self._build_model()\n",
    "        self.target_model = self._build_model()\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "        self.batch_size = 8\n",
    "        \n",
    "        # Replay buffers\n",
    "        self.replay_buffer = deque(maxlen=5000)\n",
    "        self.prioritized_replay_buffer = deque(maxlen=500)\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.gamma = 0.9\n",
    "        self.epsilon = 1.0   \n",
    "        self.epsilon_min = 0.3\n",
    "        self.epsilon_decay = 0.995\n",
    "        self.replay_rate = 10\n",
    "        self.update_beta = 0.99\n",
    "        \n",
    "        self.action_rotation_map = {\n",
    "            0: 2,\n",
    "            1: 3,\n",
    "            2: 1,\n",
    "            3: 0,\n",
    "            4: 6,\n",
    "            5: 7,\n",
    "            6: 5,\n",
    "            7: 4\n",
    "        }\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, (16,16), strides=(16,16), input_shape=self.state_size, activation='relu'))\n",
    "        model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "        model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512, activation='relu'))  \n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=\"adam\")        \n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.replay_buffer.append([state, action, reward, next_state, done])    \n",
    "        \n",
    "    def copy_to_prioritized_buffer(self, n):\n",
    "        for i in range(n):\n",
    "            self.prioritized_replay_buffer.append(self.replay_buffer[-1-i])  \n",
    "\n",
    "    def act(self, state, stochastic=False):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        \n",
    "        act_values = self.model.predict(state, verbose=0)[0]\n",
    "        \n",
    "        if stochastic:\n",
    "            act_probs = np.exp(act_values)/np.exp(act_values).sum()\n",
    "            return np.random.choice(np.arange(self.action_size), size=1, p=act_probs)[0]\n",
    "              \n",
    "        return np.argmax(act_values) \n",
    "\n",
    "    def replay(self): \n",
    "        if len(self.replay_buffer) < self.batch_size:\n",
    "            return\n",
    "        \n",
    "        if len(self.prioritized_replay_buffer) < self.batch_size//2:\n",
    "            minibatch = random.sample(self.replay_buffer, self.batch_size) \n",
    "        else:    \n",
    "            minibatch = random.sample(self.replay_buffer, self.batch_size//2) \n",
    "            minibatch.extend(random.sample(self.prioritized_replay_buffer, self.batch_size//2))\n",
    "        \n",
    "        states = np.zeros((self.batch_size*4, self.state_size[0], self.state_size[1]))\n",
    "        actions = np.zeros(self.batch_size*4, dtype=int)\n",
    "        rewards = np.zeros(self.batch_size*4)\n",
    "        next_states = np.zeros((self.batch_size*4, self.state_size[0], self.state_size[1]))\n",
    "        statuses = np.zeros(self.batch_size*4)\n",
    "        targets = np.zeros((self.batch_size*4, self.action_size)) \n",
    "        \n",
    "        for i, (state, action, reward, next_state, done) in enumerate(minibatch): \n",
    "            for rot in range(4):  \n",
    "                ind = i*4+rot\n",
    "                if rot != 0:\n",
    "                    state = np.rot90(state, axes=(1,2))\n",
    "                    next_state = np.rot90(next_state, axes=(1,2))\n",
    "                    action = self.action_rotation_map.get(action)\n",
    "\n",
    "                states[ind] = state.copy()\n",
    "                actions[ind] = action\n",
    "                rewards[ind] = reward\n",
    "                next_states[ind] = next_state.copy()\n",
    "                statuses[ind] = 1 if done else 0          \n",
    "        \n",
    "        targets = self.model.predict(states) \n",
    "        max_actions = np.argmax(self.model.predict(next_states), axis=1)\n",
    "        next_rewards = self.target_model.predict(next_states)\n",
    "        \n",
    "        ind = 0\n",
    "        for action, reward, next_reward, max_action, done in zip(actions, rewards, next_rewards, max_actions, statuses):  \n",
    "            if not done:\n",
    "                reward += self.gamma * next_reward[max_action]\n",
    "            targets[ind][action] = reward\n",
    "            ind += 1\n",
    "        \n",
    "        self.model.fit(states, targets, epochs=10, verbose=0) \n",
    "        \n",
    "        self.update_target_model()        \n",
    "    \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon = self.epsilon * self.epsilon_decay    \n",
    "        \n",
    "    def update_target_model(self):\n",
    "        model_w = self.model.get_weights()\n",
    "        target_model_w = self.target_model.get_weights()\n",
    "        updated_target_model_w = []\n",
    "        for i in range(len(model_w)):\n",
    "            updated_target_model_w.append(self.update_beta*target_model_w[i] + (1-self.update_beta)*model_w[i])\n",
    "        self.target_model.set_weights(updated_target_model_w)    \n",
    "            \n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I8TqYhBX1lD4"
   },
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    f = frame.mean(axis=2)\n",
    "    f = f / 255\n",
    "    return np.expand_dims(f, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(e, stochastic=False):\n",
    "    current_epsilon = agent.epsilon\n",
    "    agent.epsilon = 0.0\n",
    "    num_solved = 0\n",
    "    solved_in_steps = defaultdict(int)\n",
    "\n",
    "    for t in tqdm(range(100)):    \n",
    "        random.seed(t)\n",
    "        sok = PushAndPullSokobanEnv(dim_room=(7, 7), num_boxes=1)\n",
    "        sok.set_maxsteps(20)\n",
    "        steps = 0\n",
    "\n",
    "        state = sok.get_image('rgb_array')\n",
    "        done = False\n",
    "        while not done:\n",
    "            steps += 1\n",
    "            action = agent.act(process_frame(state), stochastic)\n",
    "            if action < 4:\n",
    "                action += 1\n",
    "            else:\n",
    "                action += 5\n",
    "            state, reward, done, info = sok.step(action)\n",
    "\n",
    "        if 3 in sok.room_state:            \n",
    "            num_solved += 1\n",
    "            solved_in_steps[steps] += 1\n",
    "    \n",
    "    agent.epsilon = current_epsilon    \n",
    "    print(\"Episode %d Solved: %d\" % (e+1, num_solved))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nuL03AOxCBOK"
   },
   "outputs": [],
   "source": [
    "max_episodes = 50000\n",
    "max_steps = 20\n",
    "\n",
    "def init_sok(r):\n",
    "    random.seed(r+100)\n",
    "    sok = PushAndPullSokobanEnv(dim_room=(7, 7), num_boxes=1)\n",
    "    sok.set_maxsteps(max_steps)\n",
    "    return sok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s2Km5jCqDqbz",
    "outputId": "abab4d45-7d3a-4a49-8b54-10c34549249d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 | 20\n",
      "8 | 40\n",
      "15 | 60\n",
      "23 | 80\n",
      "33 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68661722470495ea800b3f8b8a88398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 100 Solved: 52\n",
      "9 | 20\n",
      "19 | 40\n",
      "30 | 60\n",
      "39 | 80\n",
      "49 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99ccf6a262a4946bf7a57eeb84bdbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 200 Solved: 58\n",
      "10 | 20\n",
      "22 | 40\n",
      "33 | 60\n",
      "40 | 80\n",
      "49 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902f0d764f814c688c6bff34b918d3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 300 Solved: 58\n",
      "9 | 20\n",
      "20 | 40\n",
      "28 | 60\n",
      "34 | 80\n",
      "41 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331b8a2c7df5436e99e68c9de5224ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 400 Solved: 59\n",
      "12 | 20\n",
      "23 | 40\n",
      "33 | 60\n",
      "42 | 80\n",
      "52 | 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86d801b8465e4cebae181398c926487a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 500 Solved: 57\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-74f3fe06921f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maction\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msok\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-247972bdf210>\u001b[0m in \u001b[0;36mact\u001b[1;34m(self, state, stochastic)\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[0mact_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstochastic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1787\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1788\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1789\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1790\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    908\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 910\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    947\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    948\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 949\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    950\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3128\u001b[0m       (graph_function,\n\u001b[0;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3130\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1958\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1959\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     60\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = SOK_Agent()\n",
    "\n",
    "running_puzzles = 0\n",
    "running_solved = 0\n",
    "\n",
    "for e in range(max_episodes):\n",
    "    sok = init_sok(e)\n",
    "    random.seed(e)\n",
    "    running_puzzles += 1\n",
    "    \n",
    "    state = process_frame(sok.get_image('rgb_array'))\n",
    "    room_state = sok.room_state.copy() \n",
    "    distances = get_distances(room_state)\n",
    "    \n",
    "    for step in range(sok.max_steps):\n",
    "        action = agent.act(state)\n",
    "        if action < 4:\n",
    "            next_state, reward, done, _ = sok.step(action+1) \n",
    "        else:\n",
    "            next_state, reward, done, _ = sok.step(action+5)         \n",
    "        \n",
    "        next_state = process_frame(next_state)        \n",
    "        next_room_state = sok.room_state\n",
    "        \n",
    "        if not done:\n",
    "            reward += box2target_change_reward(room_state, next_room_state, distances)\n",
    "        \n",
    "        agent.remember(state, action, reward, next_state, done)\n",
    "        \n",
    "        state = next_state.copy() \n",
    "        room_state = next_room_state.copy()                \n",
    "        \n",
    "        if (step+1) % agent.replay_rate == 0:\n",
    "            agent.replay()            \n",
    "        \n",
    "        if done: \n",
    "            if 3 in sok.room_state:  \n",
    "                agent.copy_to_prioritized_buffer(step+1)  \n",
    "                running_solved += 1\n",
    "                \n",
    "            if (e+1) % 20 == 0 and e > 0:\n",
    "                print(f\"{running_solved} | {running_puzzles}\") \n",
    "                \n",
    "                if (e+1) % 100 == 0:\n",
    "                    running_puzzles = 0\n",
    "                    running_solved = 0\n",
    "                    \n",
    "            break\n",
    "            \n",
    "    if (e+1) % 100 == 0 and e > 0:\n",
    "        test_agent(e, stochastic=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
